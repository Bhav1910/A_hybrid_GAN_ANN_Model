{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 03:09:49.139589: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-21 03:09:49.143100: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-21 03:09:49.153087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732138789.170278  580323 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732138789.175260  580323 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 03:09:49.193092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_generator(latent_dim, n_features):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=latent_dim),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(n_features, activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(n_features):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_dim=n_features),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        Dense(128),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining discriminator and generator\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    model.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "2024-11-21 03:09:50.970405: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError in discriminator training: 'NoneType' object has no attribute 'update_state'\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "generator = build_generator(latent_dim, n_features)\n",
    "discriminator = build_discriminator(n_features)\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "def train_gan(gan, generator, discriminator, X_real, epochs=20000, batch_size=64):\n",
    "    # Ensure models are compiled\n",
    "    if not discriminator.compiled_metrics:\n",
    "        raise RuntimeError(\"Discriminator model is not compiled. Please compile it before training.\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Generate real and fake samples\n",
    "        idx = np.random.randint(0, X_real.shape[0], batch_size)\n",
    "        X_real_samples = X_real[idx]\n",
    "        y_real = np.ones((batch_size, 1))  # Label for real data\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        X_fake_samples = generator.predict(noise)\n",
    "        y_fake = np.zeros((batch_size, 1))  # Label for fake data\n",
    "\n",
    "        # Train discriminator\n",
    "        try:\n",
    "            discriminator_loss_real = discriminator.train_on_batch(X_real_samples, y_real)\n",
    "            discriminator_loss_fake = discriminator.train_on_batch(X_fake_samples, y_fake)\n",
    "            discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "        except AttributeError as e:\n",
    "            print(\"AttributeError in discriminator training:\", e)\n",
    "            return\n",
    "\n",
    "        # Train generator\n",
    "        try:\n",
    "            y_gan = np.ones((batch_size, 1))  # Generator aims to fool the discriminator\n",
    "            generator_loss = gan.train_on_batch(noise, y_gan)\n",
    "        except Exception as e:\n",
    "            print(\"Error during generator training:\", e)\n",
    "            return\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'Epoch {epoch}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}')\n",
    "\n",
    "\n",
    "train_gan(gan, generator, discriminator, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic samples\n",
    "noise = np.random.normal(0, 1, (len(X_train), latent_dim))\n",
    "X_synthetic = generator.predict(noise)\n",
    "y_synthetic = np.ones(len(X_synthetic))  # Use synthetic labels as '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.vstack((X_train, X_synthetic))\n",
    "y_combined = np.hstack((y_train, y_synthetic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5973 - loss: 0.6630 - val_accuracy: 1.0000 - val_loss: 0.3999\n",
      "Epoch 2/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5555 - val_accuracy: 0.9959 - val_loss: 0.2165\n",
      "Epoch 3/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.4868 - val_accuracy: 1.0000 - val_loss: 0.1052\n",
      "Epoch 4/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7654 - loss: 0.4544 - val_accuracy: 1.0000 - val_loss: 0.0579\n",
      "Epoch 5/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.4330 - val_accuracy: 1.0000 - val_loss: 0.0399\n",
      "Epoch 6/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4128 - val_accuracy: 1.0000 - val_loss: 0.0321\n",
      "Epoch 7/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4073 - val_accuracy: 1.0000 - val_loss: 0.0271\n",
      "Epoch 8/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.4000 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
      "Epoch 9/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4038 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
      "Epoch 10/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.4106 - val_accuracy: 1.0000 - val_loss: 0.0187\n",
      "Epoch 11/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4050 - val_accuracy: 1.0000 - val_loss: 0.0180\n",
      "Epoch 12/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.3741 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
      "Epoch 13/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.3651 - val_accuracy: 1.0000 - val_loss: 0.0153\n",
      "Epoch 14/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.3611 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
      "Epoch 15/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.3603 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
      "Epoch 16/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.3587 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 17/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3422 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
      "Epoch 18/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.3618 - val_accuracy: 1.0000 - val_loss: 0.0099\n",
      "Epoch 19/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3275 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
      "Epoch 20/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.3669 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 21/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.3472 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 22/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3617 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
      "Epoch 23/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3405 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 24/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.3251 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 25/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.3357 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 26/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.3223 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 27/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3272 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
      "Epoch 28/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.3361 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 29/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3191 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 30/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3070 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 31/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3174 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
      "Epoch 32/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3125 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
      "Epoch 33/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3293 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 34/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3138 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 35/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.2920 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 36/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.3252 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 37/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3037 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 38/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.3177 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 39/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.2796 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 40/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.2950 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 41/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.3001 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 42/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.2973 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 43/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.2838 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 44/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.2911 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 45/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.2902 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 46/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.2667 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 47/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.2673 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 48/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3068 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 49/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.2964 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 50/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.2803 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 51/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.2875 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 52/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.2754 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 53/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.2821 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 54/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.2766 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 55/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.2596 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 56/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.2704 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 57/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.2953 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 58/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.2859 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 59/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.2904 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 60/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.2590 - val_accuracy: 1.0000 - val_loss: 9.8758e-04\n",
      "Epoch 61/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.2741 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 62/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.2802 - val_accuracy: 1.0000 - val_loss: 8.1425e-04\n",
      "Epoch 63/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.2986 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 64/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.2944 - val_accuracy: 1.0000 - val_loss: 9.0815e-04\n",
      "Epoch 65/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.2800 - val_accuracy: 1.0000 - val_loss: 7.9617e-04\n",
      "Epoch 66/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.2706 - val_accuracy: 1.0000 - val_loss: 7.0555e-04\n",
      "Epoch 67/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.2634 - val_accuracy: 1.0000 - val_loss: 8.2826e-04\n",
      "Epoch 68/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.2747 - val_accuracy: 1.0000 - val_loss: 6.9054e-04\n",
      "Epoch 69/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8499 - loss: 0.2981 - val_accuracy: 1.0000 - val_loss: 7.7746e-04\n",
      "Epoch 70/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.2900 - val_accuracy: 1.0000 - val_loss: 6.8502e-04\n",
      "Epoch 71/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.2907 - val_accuracy: 1.0000 - val_loss: 7.6510e-04\n",
      "Epoch 72/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.2866 - val_accuracy: 1.0000 - val_loss: 6.2713e-04\n",
      "Epoch 73/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.2810 - val_accuracy: 1.0000 - val_loss: 6.4987e-04\n",
      "Epoch 74/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.2747 - val_accuracy: 1.0000 - val_loss: 4.8517e-04\n",
      "Epoch 75/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.2829 - val_accuracy: 1.0000 - val_loss: 4.3468e-04\n",
      "Epoch 76/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.2773 - val_accuracy: 1.0000 - val_loss: 4.9512e-04\n",
      "Epoch 77/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.2641 - val_accuracy: 1.0000 - val_loss: 5.2989e-04\n",
      "Epoch 78/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.2709 - val_accuracy: 1.0000 - val_loss: 4.7445e-04\n",
      "Epoch 79/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.2631 - val_accuracy: 1.0000 - val_loss: 4.1603e-04\n",
      "Epoch 80/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.2664 - val_accuracy: 1.0000 - val_loss: 3.8184e-04\n",
      "Epoch 81/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.2736 - val_accuracy: 1.0000 - val_loss: 3.3529e-04\n",
      "Epoch 82/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.2566 - val_accuracy: 1.0000 - val_loss: 3.3671e-04\n",
      "Epoch 83/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.2960 - val_accuracy: 1.0000 - val_loss: 3.7106e-04\n",
      "Epoch 84/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.2719 - val_accuracy: 1.0000 - val_loss: 2.8559e-04\n",
      "Epoch 85/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.2707 - val_accuracy: 1.0000 - val_loss: 3.1653e-04\n",
      "Epoch 86/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.2539 - val_accuracy: 1.0000 - val_loss: 2.8329e-04\n",
      "Epoch 87/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.2857 - val_accuracy: 1.0000 - val_loss: 2.7151e-04\n",
      "Epoch 88/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.2461 - val_accuracy: 1.0000 - val_loss: 2.7781e-04\n",
      "Epoch 89/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.2608 - val_accuracy: 1.0000 - val_loss: 2.7605e-04\n",
      "Epoch 90/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.2623 - val_accuracy: 1.0000 - val_loss: 2.5893e-04\n",
      "Epoch 91/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.2594 - val_accuracy: 1.0000 - val_loss: 2.8889e-04\n",
      "Epoch 92/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.2671 - val_accuracy: 1.0000 - val_loss: 2.3164e-04\n",
      "Epoch 93/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2548 - val_accuracy: 1.0000 - val_loss: 1.6972e-04\n",
      "Epoch 94/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.2681 - val_accuracy: 1.0000 - val_loss: 2.1270e-04\n",
      "Epoch 95/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.2712 - val_accuracy: 1.0000 - val_loss: 2.0541e-04\n",
      "Epoch 96/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.2734 - val_accuracy: 1.0000 - val_loss: 2.2467e-04\n",
      "Epoch 97/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8752 - loss: 0.2614 - val_accuracy: 1.0000 - val_loss: 2.1962e-04\n",
      "Epoch 98/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2579 - val_accuracy: 1.0000 - val_loss: 1.9665e-04\n",
      "Epoch 99/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.2731 - val_accuracy: 1.0000 - val_loss: 2.2969e-04\n",
      "Epoch 100/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.2449 - val_accuracy: 1.0000 - val_loss: 1.8447e-04\n",
      "Epoch 101/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8886 - loss: 0.2579 - val_accuracy: 1.0000 - val_loss: 1.6056e-04\n",
      "Epoch 102/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2592 - val_accuracy: 1.0000 - val_loss: 1.4621e-04\n",
      "Epoch 103/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.2605 - val_accuracy: 1.0000 - val_loss: 1.0953e-04\n",
      "Epoch 104/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.2623 - val_accuracy: 1.0000 - val_loss: 1.4045e-04\n",
      "Epoch 105/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.2713 - val_accuracy: 1.0000 - val_loss: 1.3292e-04\n",
      "Epoch 106/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.2689 - val_accuracy: 1.0000 - val_loss: 1.3129e-04\n",
      "Epoch 107/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2428 - val_accuracy: 1.0000 - val_loss: 1.0874e-04\n",
      "Epoch 108/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.2719 - val_accuracy: 1.0000 - val_loss: 1.0468e-04\n",
      "Epoch 109/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.2462 - val_accuracy: 1.0000 - val_loss: 1.0177e-04\n",
      "Epoch 110/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.2664 - val_accuracy: 1.0000 - val_loss: 8.0992e-05\n",
      "Epoch 111/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.2499 - val_accuracy: 1.0000 - val_loss: 9.1376e-05\n",
      "Epoch 112/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.2759 - val_accuracy: 1.0000 - val_loss: 9.4116e-05\n",
      "Epoch 113/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.2655 - val_accuracy: 1.0000 - val_loss: 9.8133e-05\n",
      "Epoch 114/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2629 - val_accuracy: 1.0000 - val_loss: 7.2477e-05\n",
      "Epoch 115/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.2707 - val_accuracy: 1.0000 - val_loss: 7.2596e-05\n",
      "Epoch 116/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.2541 - val_accuracy: 1.0000 - val_loss: 6.1505e-05\n",
      "Epoch 117/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2403 - val_accuracy: 1.0000 - val_loss: 4.7927e-05\n",
      "Epoch 118/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.2769 - val_accuracy: 1.0000 - val_loss: 5.8694e-05\n",
      "Epoch 119/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.2840 - val_accuracy: 1.0000 - val_loss: 4.8000e-05\n",
      "Epoch 120/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.2387 - val_accuracy: 1.0000 - val_loss: 4.9185e-05\n",
      "Epoch 121/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.2851 - val_accuracy: 1.0000 - val_loss: 6.0258e-05\n",
      "Epoch 122/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.2531 - val_accuracy: 1.0000 - val_loss: 4.7781e-05\n",
      "Epoch 123/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2483 - val_accuracy: 1.0000 - val_loss: 4.8391e-05\n",
      "Epoch 124/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.2558 - val_accuracy: 1.0000 - val_loss: 3.8244e-05\n",
      "Epoch 125/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.2578 - val_accuracy: 1.0000 - val_loss: 5.3692e-05\n",
      "Epoch 126/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2560 - val_accuracy: 1.0000 - val_loss: 4.4774e-05\n",
      "Epoch 127/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2573 - val_accuracy: 1.0000 - val_loss: 4.3879e-05\n",
      "Epoch 128/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.2560 - val_accuracy: 1.0000 - val_loss: 3.4369e-05\n",
      "Epoch 129/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8803 - loss: 0.2606 - val_accuracy: 1.0000 - val_loss: 2.7321e-05\n",
      "Epoch 130/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2562 - val_accuracy: 1.0000 - val_loss: 2.9261e-05\n",
      "Epoch 131/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8852 - loss: 0.2468 - val_accuracy: 1.0000 - val_loss: 3.2602e-05\n",
      "Epoch 132/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 0.2679 - val_accuracy: 1.0000 - val_loss: 2.3750e-05\n",
      "Epoch 133/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.2639 - val_accuracy: 1.0000 - val_loss: 2.8398e-05\n",
      "Epoch 134/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.2643 - val_accuracy: 1.0000 - val_loss: 2.2301e-05\n",
      "Epoch 135/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2407 - val_accuracy: 1.0000 - val_loss: 2.0001e-05\n",
      "Epoch 136/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.2640 - val_accuracy: 1.0000 - val_loss: 1.8645e-05\n",
      "Epoch 137/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2450 - val_accuracy: 1.0000 - val_loss: 2.0597e-05\n",
      "Epoch 138/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.2610 - val_accuracy: 1.0000 - val_loss: 2.2896e-05\n",
      "Epoch 139/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.2681 - val_accuracy: 1.0000 - val_loss: 1.9513e-05\n",
      "Epoch 140/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2597 - val_accuracy: 1.0000 - val_loss: 1.6311e-05\n",
      "Epoch 141/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.2581 - val_accuracy: 1.0000 - val_loss: 1.8736e-05\n",
      "Epoch 142/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2400 - val_accuracy: 1.0000 - val_loss: 1.4925e-05\n",
      "Epoch 143/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2293 - val_accuracy: 1.0000 - val_loss: 1.5510e-05\n",
      "Epoch 144/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.2525 - val_accuracy: 1.0000 - val_loss: 2.0333e-05\n",
      "Epoch 145/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.2796 - val_accuracy: 1.0000 - val_loss: 1.6602e-05\n",
      "Epoch 146/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.2410 - val_accuracy: 1.0000 - val_loss: 1.9983e-05\n",
      "Epoch 147/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2504 - val_accuracy: 1.0000 - val_loss: 2.0655e-05\n",
      "Epoch 148/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.2470 - val_accuracy: 1.0000 - val_loss: 1.7367e-05\n",
      "Epoch 149/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2234 - val_accuracy: 1.0000 - val_loss: 1.0296e-05\n",
      "Epoch 150/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.2558 - val_accuracy: 1.0000 - val_loss: 1.0271e-05\n",
      "Epoch 151/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.2271 - val_accuracy: 1.0000 - val_loss: 1.2051e-05\n",
      "Epoch 152/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.2471 - val_accuracy: 1.0000 - val_loss: 1.1068e-05\n",
      "Epoch 153/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.2524 - val_accuracy: 1.0000 - val_loss: 1.4766e-05\n",
      "Epoch 154/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.2498 - val_accuracy: 1.0000 - val_loss: 9.3102e-06\n",
      "Epoch 155/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.2509 - val_accuracy: 1.0000 - val_loss: 8.6048e-06\n",
      "Epoch 156/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2484 - val_accuracy: 1.0000 - val_loss: 8.4535e-06\n",
      "Epoch 157/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.2541 - val_accuracy: 1.0000 - val_loss: 8.3211e-06\n",
      "Epoch 158/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2414 - val_accuracy: 1.0000 - val_loss: 8.6860e-06\n",
      "Epoch 159/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.2529 - val_accuracy: 1.0000 - val_loss: 7.3006e-06\n",
      "Epoch 160/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2235 - val_accuracy: 1.0000 - val_loss: 6.7644e-06\n",
      "Epoch 161/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.2483 - val_accuracy: 1.0000 - val_loss: 5.2853e-06\n",
      "Epoch 162/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2358 - val_accuracy: 1.0000 - val_loss: 6.2222e-06\n",
      "Epoch 163/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.2681 - val_accuracy: 1.0000 - val_loss: 6.0864e-06\n",
      "Epoch 164/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2305 - val_accuracy: 1.0000 - val_loss: 9.1807e-06\n",
      "Epoch 165/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2296 - val_accuracy: 1.0000 - val_loss: 6.5099e-06\n",
      "Epoch 166/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.2641 - val_accuracy: 1.0000 - val_loss: 6.2359e-06\n",
      "Epoch 167/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2272 - val_accuracy: 1.0000 - val_loss: 4.0150e-06\n",
      "Epoch 168/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.2464 - val_accuracy: 1.0000 - val_loss: 8.0833e-06\n",
      "Epoch 169/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.2511 - val_accuracy: 1.0000 - val_loss: 5.5445e-06\n",
      "Epoch 170/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2381 - val_accuracy: 1.0000 - val_loss: 4.5289e-06\n",
      "Epoch 171/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2419 - val_accuracy: 1.0000 - val_loss: 3.1683e-06\n",
      "Epoch 172/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.2305 - val_accuracy: 1.0000 - val_loss: 3.5014e-06\n",
      "Epoch 173/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.2433 - val_accuracy: 1.0000 - val_loss: 3.0310e-06\n",
      "Epoch 174/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2542 - val_accuracy: 1.0000 - val_loss: 4.7390e-06\n",
      "Epoch 175/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.2599 - val_accuracy: 1.0000 - val_loss: 2.3986e-06\n",
      "Epoch 176/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.2476 - val_accuracy: 1.0000 - val_loss: 2.5131e-06\n",
      "Epoch 177/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2562 - val_accuracy: 1.0000 - val_loss: 1.2543e-06\n",
      "Epoch 178/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.2384 - val_accuracy: 1.0000 - val_loss: 2.4186e-06\n",
      "Epoch 179/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.2278 - val_accuracy: 1.0000 - val_loss: 1.3193e-06\n",
      "Epoch 180/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2168 - val_accuracy: 1.0000 - val_loss: 2.3445e-06\n",
      "Epoch 181/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2324 - val_accuracy: 1.0000 - val_loss: 1.9456e-06\n",
      "Epoch 182/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.2478 - val_accuracy: 1.0000 - val_loss: 1.7714e-06\n",
      "Epoch 183/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2306 - val_accuracy: 1.0000 - val_loss: 1.3788e-06\n",
      "Epoch 184/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 0.2559 - val_accuracy: 1.0000 - val_loss: 1.5016e-06\n",
      "Epoch 185/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2408 - val_accuracy: 1.0000 - val_loss: 1.5321e-06\n",
      "Epoch 186/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.2495 - val_accuracy: 1.0000 - val_loss: 1.8308e-06\n",
      "Epoch 187/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2205 - val_accuracy: 1.0000 - val_loss: 9.8635e-07\n",
      "Epoch 188/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2356 - val_accuracy: 1.0000 - val_loss: 8.7848e-07\n",
      "Epoch 189/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2222 - val_accuracy: 1.0000 - val_loss: 9.5366e-07\n",
      "Epoch 190/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.2499 - val_accuracy: 1.0000 - val_loss: 1.5647e-06\n",
      "Epoch 191/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.2214 - val_accuracy: 1.0000 - val_loss: 8.9204e-07\n",
      "Epoch 192/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.2404 - val_accuracy: 1.0000 - val_loss: 1.3423e-06\n",
      "Epoch 193/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2325 - val_accuracy: 1.0000 - val_loss: 1.1667e-06\n",
      "Epoch 194/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.2523 - val_accuracy: 1.0000 - val_loss: 8.4106e-07\n",
      "Epoch 195/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2363 - val_accuracy: 1.0000 - val_loss: 8.1825e-07\n",
      "Epoch 196/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.2510 - val_accuracy: 1.0000 - val_loss: 7.2346e-07\n",
      "Epoch 197/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.2541 - val_accuracy: 1.0000 - val_loss: 9.7947e-07\n",
      "Epoch 198/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.2515 - val_accuracy: 1.0000 - val_loss: 8.5087e-07\n",
      "Epoch 199/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2364 - val_accuracy: 1.0000 - val_loss: 8.4587e-07\n",
      "Epoch 200/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2323 - val_accuracy: 1.0000 - val_loss: 7.0952e-07\n",
      "Epoch 201/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2352 - val_accuracy: 1.0000 - val_loss: 5.0342e-07\n",
      "Epoch 202/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2335 - val_accuracy: 1.0000 - val_loss: 7.5976e-07\n",
      "Epoch 203/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2295 - val_accuracy: 1.0000 - val_loss: 9.3451e-07\n",
      "Epoch 204/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2444 - val_accuracy: 1.0000 - val_loss: 6.8163e-07\n",
      "Epoch 205/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2297 - val_accuracy: 1.0000 - val_loss: 7.5804e-07\n",
      "Epoch 206/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8765 - loss: 0.2417 - val_accuracy: 1.0000 - val_loss: 7.8153e-07\n",
      "Epoch 207/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.2440 - val_accuracy: 1.0000 - val_loss: 9.0081e-07\n",
      "Epoch 208/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.2454 - val_accuracy: 1.0000 - val_loss: 8.5355e-07\n",
      "Epoch 209/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2502 - val_accuracy: 1.0000 - val_loss: 9.0712e-07\n",
      "Epoch 210/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.2465 - val_accuracy: 1.0000 - val_loss: 5.8147e-07\n",
      "Epoch 211/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.2263 - val_accuracy: 1.0000 - val_loss: 5.6034e-07\n",
      "Epoch 212/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.2433 - val_accuracy: 1.0000 - val_loss: 7.1766e-07\n",
      "Epoch 213/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2279 - val_accuracy: 1.0000 - val_loss: 5.8728e-07\n",
      "Epoch 214/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2306 - val_accuracy: 1.0000 - val_loss: 4.8792e-07\n",
      "Epoch 215/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8907 - loss: 0.2331 - val_accuracy: 1.0000 - val_loss: 4.5725e-07\n",
      "Epoch 216/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2200 - val_accuracy: 1.0000 - val_loss: 3.7741e-07\n",
      "Epoch 217/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2115 - val_accuracy: 1.0000 - val_loss: 1.9840e-07\n",
      "Epoch 218/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2336 - val_accuracy: 1.0000 - val_loss: 2.3256e-07\n",
      "Epoch 219/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2181 - val_accuracy: 1.0000 - val_loss: 2.4405e-07\n",
      "Epoch 220/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2269 - val_accuracy: 1.0000 - val_loss: 2.6878e-07\n",
      "Epoch 221/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2311 - val_accuracy: 1.0000 - val_loss: 3.1814e-07\n",
      "Epoch 222/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.2393 - val_accuracy: 1.0000 - val_loss: 1.1704e-07\n",
      "Epoch 223/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2253 - val_accuracy: 1.0000 - val_loss: 3.4495e-07\n",
      "Epoch 224/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.2411 - val_accuracy: 1.0000 - val_loss: 3.0312e-07\n",
      "Epoch 225/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2204 - val_accuracy: 1.0000 - val_loss: 3.4788e-07\n",
      "Epoch 226/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2375 - val_accuracy: 1.0000 - val_loss: 2.8438e-07\n",
      "Epoch 227/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2132 - val_accuracy: 1.0000 - val_loss: 2.2755e-07\n",
      "Epoch 228/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2436 - val_accuracy: 1.0000 - val_loss: 1.4065e-07\n",
      "Epoch 229/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2172 - val_accuracy: 1.0000 - val_loss: 1.6265e-07\n",
      "Epoch 230/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2222 - val_accuracy: 1.0000 - val_loss: 1.4780e-07\n",
      "Epoch 231/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.2429 - val_accuracy: 1.0000 - val_loss: 1.6071e-07\n",
      "Epoch 232/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2239 - val_accuracy: 1.0000 - val_loss: 1.7928e-07\n",
      "Epoch 233/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2248 - val_accuracy: 1.0000 - val_loss: 1.1817e-07\n",
      "Epoch 234/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2278 - val_accuracy: 1.0000 - val_loss: 2.8514e-07\n",
      "Epoch 235/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2242 - val_accuracy: 1.0000 - val_loss: 2.1286e-07\n",
      "Epoch 236/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.2228 - val_accuracy: 1.0000 - val_loss: 2.1163e-07\n",
      "Epoch 237/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.2448 - val_accuracy: 1.0000 - val_loss: 2.5368e-07\n",
      "Epoch 238/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2327 - val_accuracy: 1.0000 - val_loss: 4.0901e-07\n",
      "Epoch 239/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2182 - val_accuracy: 1.0000 - val_loss: 2.8466e-07\n",
      "Epoch 240/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2339 - val_accuracy: 1.0000 - val_loss: 3.0299e-07\n",
      "Epoch 241/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.2351 - val_accuracy: 1.0000 - val_loss: 2.5811e-07\n",
      "Epoch 242/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2310 - val_accuracy: 1.0000 - val_loss: 1.7892e-07\n",
      "Epoch 243/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2223 - val_accuracy: 1.0000 - val_loss: 1.7985e-07\n",
      "Epoch 244/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.2342 - val_accuracy: 1.0000 - val_loss: 2.4984e-07\n",
      "Epoch 245/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2146 - val_accuracy: 1.0000 - val_loss: 1.4358e-07\n",
      "Epoch 246/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2304 - val_accuracy: 1.0000 - val_loss: 1.7426e-07\n",
      "Epoch 247/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.2418 - val_accuracy: 1.0000 - val_loss: 1.3705e-07\n",
      "Epoch 248/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2222 - val_accuracy: 1.0000 - val_loss: 2.1118e-07\n",
      "Epoch 249/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.2423 - val_accuracy: 1.0000 - val_loss: 1.4360e-07\n",
      "Epoch 250/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2204 - val_accuracy: 1.0000 - val_loss: 1.5120e-07\n",
      "Epoch 251/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2309 - val_accuracy: 1.0000 - val_loss: 1.2120e-07\n",
      "Epoch 252/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.2751 - val_accuracy: 1.0000 - val_loss: 9.2276e-08\n",
      "Epoch 253/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2247 - val_accuracy: 1.0000 - val_loss: 7.5741e-08\n",
      "Epoch 254/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.2436 - val_accuracy: 1.0000 - val_loss: 1.2648e-07\n",
      "Epoch 255/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2092 - val_accuracy: 1.0000 - val_loss: 8.6050e-08\n",
      "Epoch 256/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.2459 - val_accuracy: 1.0000 - val_loss: 2.1677e-07\n",
      "Epoch 257/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.2614 - val_accuracy: 1.0000 - val_loss: 1.3434e-07\n",
      "Epoch 258/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2342 - val_accuracy: 1.0000 - val_loss: 2.1738e-07\n",
      "Epoch 259/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.2347 - val_accuracy: 1.0000 - val_loss: 1.7698e-07\n",
      "Epoch 260/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2274 - val_accuracy: 1.0000 - val_loss: 9.1678e-08\n",
      "Epoch 261/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2273 - val_accuracy: 1.0000 - val_loss: 1.3716e-07\n",
      "Epoch 262/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.2050 - val_accuracy: 1.0000 - val_loss: 7.1668e-08\n",
      "Epoch 263/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2380 - val_accuracy: 1.0000 - val_loss: 7.2152e-08\n",
      "Epoch 264/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.2300 - val_accuracy: 1.0000 - val_loss: 9.7449e-08\n",
      "Epoch 265/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2344 - val_accuracy: 1.0000 - val_loss: 3.1260e-08\n",
      "Epoch 266/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2448 - val_accuracy: 1.0000 - val_loss: 2.9476e-08\n",
      "Epoch 267/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2472 - val_accuracy: 1.0000 - val_loss: 5.4571e-08\n",
      "Epoch 268/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.1963 - val_accuracy: 1.0000 - val_loss: 2.3182e-08\n",
      "Epoch 269/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2391 - val_accuracy: 1.0000 - val_loss: 2.2178e-08\n",
      "Epoch 270/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2209 - val_accuracy: 1.0000 - val_loss: 4.8701e-08\n",
      "Epoch 271/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.2366 - val_accuracy: 1.0000 - val_loss: 2.7751e-08\n",
      "Epoch 272/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2052 - val_accuracy: 1.0000 - val_loss: 2.5248e-08\n",
      "Epoch 273/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2272 - val_accuracy: 1.0000 - val_loss: 2.1636e-08\n",
      "Epoch 274/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2407 - val_accuracy: 1.0000 - val_loss: 1.7944e-08\n",
      "Epoch 275/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2405 - val_accuracy: 1.0000 - val_loss: 2.2466e-08\n",
      "Epoch 276/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2091 - val_accuracy: 1.0000 - val_loss: 1.5712e-08\n",
      "Epoch 277/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2258 - val_accuracy: 1.0000 - val_loss: 9.8183e-09\n",
      "Epoch 278/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.2216 - val_accuracy: 1.0000 - val_loss: 1.5691e-08\n",
      "Epoch 279/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2376 - val_accuracy: 1.0000 - val_loss: 1.6206e-08\n",
      "Epoch 280/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2173 - val_accuracy: 1.0000 - val_loss: 1.2582e-08\n",
      "Epoch 281/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2048 - val_accuracy: 1.0000 - val_loss: 1.3125e-08\n",
      "Epoch 282/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2321 - val_accuracy: 1.0000 - val_loss: 1.9538e-08\n",
      "Epoch 283/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2087 - val_accuracy: 1.0000 - val_loss: 1.6957e-08\n",
      "Epoch 284/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2107 - val_accuracy: 1.0000 - val_loss: 8.6710e-09\n",
      "Epoch 285/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2105 - val_accuracy: 1.0000 - val_loss: 1.3991e-08\n",
      "Epoch 286/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2086 - val_accuracy: 1.0000 - val_loss: 8.0705e-09\n",
      "Epoch 287/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.2179 - val_accuracy: 1.0000 - val_loss: 6.8379e-09\n",
      "Epoch 288/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2117 - val_accuracy: 1.0000 - val_loss: 5.8396e-09\n",
      "Epoch 289/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.2445 - val_accuracy: 1.0000 - val_loss: 4.9086e-09\n",
      "Epoch 290/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.2396 - val_accuracy: 1.0000 - val_loss: 4.1440e-09\n",
      "Epoch 291/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2074 - val_accuracy: 1.0000 - val_loss: 4.0901e-09\n",
      "Epoch 292/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2217 - val_accuracy: 1.0000 - val_loss: 7.5535e-09\n",
      "Epoch 293/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2053 - val_accuracy: 1.0000 - val_loss: 5.9081e-09\n",
      "Epoch 294/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.2156 - val_accuracy: 1.0000 - val_loss: 1.3390e-08\n",
      "Epoch 295/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2195 - val_accuracy: 1.0000 - val_loss: 1.0774e-08\n",
      "Epoch 296/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2003 - val_accuracy: 1.0000 - val_loss: 6.9897e-09\n",
      "Epoch 297/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2194 - val_accuracy: 1.0000 - val_loss: 8.3668e-09\n",
      "Epoch 298/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.2156 - val_accuracy: 1.0000 - val_loss: 6.3050e-09\n",
      "Epoch 299/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2084 - val_accuracy: 1.0000 - val_loss: 4.0818e-09\n",
      "Epoch 300/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.2226 - val_accuracy: 1.0000 - val_loss: 4.0462e-09\n",
      "Epoch 301/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2026 - val_accuracy: 1.0000 - val_loss: 3.5646e-09\n",
      "Epoch 302/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2034 - val_accuracy: 1.0000 - val_loss: 3.3399e-09\n",
      "Epoch 303/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2037 - val_accuracy: 1.0000 - val_loss: 3.9307e-09\n",
      "Epoch 304/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1999 - val_accuracy: 1.0000 - val_loss: 5.6547e-09\n",
      "Epoch 305/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2146 - val_accuracy: 1.0000 - val_loss: 2.6914e-09\n",
      "Epoch 306/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2109 - val_accuracy: 1.0000 - val_loss: 4.8274e-09\n",
      "Epoch 307/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2534 - val_accuracy: 1.0000 - val_loss: 6.5978e-09\n",
      "Epoch 308/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.2258 - val_accuracy: 1.0000 - val_loss: 4.9937e-09\n",
      "Epoch 309/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2029 - val_accuracy: 1.0000 - val_loss: 3.4481e-09\n",
      "Epoch 310/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2223 - val_accuracy: 1.0000 - val_loss: 2.9781e-09\n",
      "Epoch 311/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2218 - val_accuracy: 1.0000 - val_loss: 4.4468e-09\n",
      "Epoch 312/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.1955 - val_accuracy: 1.0000 - val_loss: 3.0146e-09\n",
      "Epoch 313/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2201 - val_accuracy: 1.0000 - val_loss: 2.3883e-09\n",
      "Epoch 314/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2118 - val_accuracy: 1.0000 - val_loss: 1.9213e-09\n",
      "Epoch 315/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2167 - val_accuracy: 1.0000 - val_loss: 2.2021e-09\n",
      "Epoch 316/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2250 - val_accuracy: 1.0000 - val_loss: 1.6730e-09\n",
      "Epoch 317/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2028 - val_accuracy: 1.0000 - val_loss: 1.9452e-09\n",
      "Epoch 318/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2320 - val_accuracy: 1.0000 - val_loss: 1.1827e-09\n",
      "Epoch 319/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2185 - val_accuracy: 1.0000 - val_loss: 3.1490e-09\n",
      "Epoch 320/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.2202 - val_accuracy: 1.0000 - val_loss: 1.4267e-09\n",
      "Epoch 321/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2126 - val_accuracy: 1.0000 - val_loss: 1.4975e-09\n",
      "Epoch 322/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2024 - val_accuracy: 1.0000 - val_loss: 1.1308e-09\n",
      "Epoch 323/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2154 - val_accuracy: 1.0000 - val_loss: 8.5183e-10\n",
      "Epoch 324/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2319 - val_accuracy: 1.0000 - val_loss: 8.4809e-10\n",
      "Epoch 325/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2238 - val_accuracy: 1.0000 - val_loss: 6.7411e-10\n",
      "Epoch 326/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2072 - val_accuracy: 1.0000 - val_loss: 8.1854e-10\n",
      "Epoch 327/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2316 - val_accuracy: 1.0000 - val_loss: 5.0725e-10\n",
      "Epoch 328/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2078 - val_accuracy: 1.0000 - val_loss: 7.9362e-10\n",
      "Epoch 329/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2181 - val_accuracy: 1.0000 - val_loss: 5.6354e-10\n",
      "Epoch 330/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2109 - val_accuracy: 1.0000 - val_loss: 1.0756e-09\n",
      "Epoch 331/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2153 - val_accuracy: 1.0000 - val_loss: 4.4110e-10\n",
      "Epoch 332/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2115 - val_accuracy: 1.0000 - val_loss: 1.9780e-10\n",
      "Epoch 333/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2004 - val_accuracy: 1.0000 - val_loss: 3.4179e-10\n",
      "Epoch 334/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.1980 - val_accuracy: 1.0000 - val_loss: 5.6015e-10\n",
      "Epoch 335/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2094 - val_accuracy: 1.0000 - val_loss: 7.1800e-10\n",
      "Epoch 336/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.1848 - val_accuracy: 1.0000 - val_loss: 1.9195e-10\n",
      "Epoch 337/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2005 - val_accuracy: 1.0000 - val_loss: 3.3362e-10\n",
      "Epoch 338/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2024 - val_accuracy: 1.0000 - val_loss: 1.5056e-10\n",
      "Epoch 339/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2183 - val_accuracy: 1.0000 - val_loss: 4.7276e-10\n",
      "Epoch 340/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2058 - val_accuracy: 1.0000 - val_loss: 2.6988e-10\n",
      "Epoch 341/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2091 - val_accuracy: 1.0000 - val_loss: 2.3566e-10\n",
      "Epoch 342/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2282 - val_accuracy: 1.0000 - val_loss: 1.9944e-10\n",
      "Epoch 343/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.1939 - val_accuracy: 1.0000 - val_loss: 2.5211e-10\n",
      "Epoch 344/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.2078 - val_accuracy: 1.0000 - val_loss: 5.3060e-10\n",
      "Epoch 345/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.1999 - val_accuracy: 1.0000 - val_loss: 1.5927e-10\n",
      "Epoch 346/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2059 - val_accuracy: 1.0000 - val_loss: 2.8531e-10\n",
      "Epoch 347/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2221 - val_accuracy: 1.0000 - val_loss: 1.6334e-10\n",
      "Epoch 348/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.1973 - val_accuracy: 1.0000 - val_loss: 2.3103e-10\n",
      "Epoch 349/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.1973 - val_accuracy: 1.0000 - val_loss: 2.5455e-10\n",
      "Epoch 350/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2055 - val_accuracy: 1.0000 - val_loss: 3.2785e-10\n",
      "Epoch 351/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.1975 - val_accuracy: 1.0000 - val_loss: 2.4908e-10\n",
      "Epoch 352/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2051 - val_accuracy: 1.0000 - val_loss: 3.6358e-10\n",
      "Epoch 353/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.1880 - val_accuracy: 1.0000 - val_loss: 3.7284e-10\n",
      "Epoch 354/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2264 - val_accuracy: 1.0000 - val_loss: 4.1325e-10\n",
      "Epoch 355/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2312 - val_accuracy: 1.0000 - val_loss: 2.1237e-10\n",
      "Epoch 356/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2020 - val_accuracy: 1.0000 - val_loss: 2.7114e-10\n",
      "Epoch 357/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.1961 - val_accuracy: 1.0000 - val_loss: 2.1223e-10\n",
      "Epoch 358/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2030 - val_accuracy: 1.0000 - val_loss: 1.6909e-10\n",
      "Epoch 359/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2013 - val_accuracy: 1.0000 - val_loss: 1.3637e-10\n",
      "Epoch 360/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2213 - val_accuracy: 1.0000 - val_loss: 1.0319e-10\n",
      "Epoch 361/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.1817 - val_accuracy: 1.0000 - val_loss: 6.5672e-11\n",
      "Epoch 362/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.1911 - val_accuracy: 1.0000 - val_loss: 1.0866e-11\n",
      "Epoch 363/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2234 - val_accuracy: 1.0000 - val_loss: 2.3666e-11\n",
      "Epoch 364/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.2119 - val_accuracy: 1.0000 - val_loss: 3.7013e-11\n",
      "Epoch 365/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.1974 - val_accuracy: 1.0000 - val_loss: 2.3792e-11\n",
      "Epoch 366/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2089 - val_accuracy: 1.0000 - val_loss: 1.8623e-11\n",
      "Epoch 367/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2085 - val_accuracy: 1.0000 - val_loss: 2.0586e-11\n",
      "Epoch 368/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2215 - val_accuracy: 1.0000 - val_loss: 2.8893e-11\n",
      "Epoch 369/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.1976 - val_accuracy: 1.0000 - val_loss: 1.7853e-11\n",
      "Epoch 370/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2066 - val_accuracy: 1.0000 - val_loss: 1.5142e-11\n",
      "Epoch 371/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2060 - val_accuracy: 1.0000 - val_loss: 1.0170e-11\n",
      "Epoch 372/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2200 - val_accuracy: 1.0000 - val_loss: 1.1880e-11\n",
      "Epoch 373/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.1853 - val_accuracy: 1.0000 - val_loss: 7.6016e-12\n",
      "Epoch 374/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.1894 - val_accuracy: 1.0000 - val_loss: 9.7943e-12\n",
      "Epoch 375/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2138 - val_accuracy: 1.0000 - val_loss: 6.0796e-12\n",
      "Epoch 376/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.1917 - val_accuracy: 1.0000 - val_loss: 6.5334e-12\n",
      "Epoch 377/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.1985 - val_accuracy: 1.0000 - val_loss: 4.9308e-12\n",
      "Epoch 378/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2195 - val_accuracy: 1.0000 - val_loss: 4.2860e-12\n",
      "Epoch 379/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2006 - val_accuracy: 1.0000 - val_loss: 3.2413e-12\n",
      "Epoch 380/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.1945 - val_accuracy: 1.0000 - val_loss: 4.8169e-12\n",
      "Epoch 381/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.2167 - val_accuracy: 1.0000 - val_loss: 2.5938e-12\n",
      "Epoch 382/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.1879 - val_accuracy: 1.0000 - val_loss: 7.2866e-12\n",
      "Epoch 383/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.2023 - val_accuracy: 1.0000 - val_loss: 4.7882e-12\n",
      "Epoch 384/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.1940 - val_accuracy: 1.0000 - val_loss: 5.4893e-12\n",
      "Epoch 385/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.1975 - val_accuracy: 1.0000 - val_loss: 5.3622e-12\n",
      "Epoch 386/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.1805 - val_accuracy: 1.0000 - val_loss: 2.9475e-12\n",
      "Epoch 387/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9020 - loss: 0.2115 - val_accuracy: 1.0000 - val_loss: 3.0929e-12\n",
      "Epoch 388/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.1792 - val_accuracy: 1.0000 - val_loss: 2.1344e-12\n",
      "Epoch 389/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2049 - val_accuracy: 1.0000 - val_loss: 1.0581e-12\n",
      "Epoch 390/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2029 - val_accuracy: 1.0000 - val_loss: 1.3285e-12\n",
      "Epoch 391/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.1883 - val_accuracy: 1.0000 - val_loss: 1.7716e-12\n",
      "Epoch 392/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2106 - val_accuracy: 1.0000 - val_loss: 2.7914e-12\n",
      "Epoch 393/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2058 - val_accuracy: 1.0000 - val_loss: 1.3214e-12\n",
      "Epoch 394/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.1961 - val_accuracy: 1.0000 - val_loss: 1.3130e-12\n",
      "Epoch 395/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.1990 - val_accuracy: 1.0000 - val_loss: 8.3377e-13\n",
      "Epoch 396/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.1879 - val_accuracy: 1.0000 - val_loss: 2.2985e-12\n",
      "Epoch 397/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.2040 - val_accuracy: 1.0000 - val_loss: 2.2036e-12\n",
      "Epoch 398/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2094 - val_accuracy: 1.0000 - val_loss: 1.7725e-12\n",
      "Epoch 399/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.1812 - val_accuracy: 1.0000 - val_loss: 2.1462e-12\n",
      "Epoch 400/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.1886 - val_accuracy: 1.0000 - val_loss: 1.7001e-12\n",
      "Epoch 401/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.1830 - val_accuracy: 1.0000 - val_loss: 1.8144e-12\n",
      "Epoch 402/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2213 - val_accuracy: 1.0000 - val_loss: 1.6868e-12\n",
      "Epoch 403/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.1887 - val_accuracy: 1.0000 - val_loss: 1.7600e-12\n",
      "Epoch 404/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.2126 - val_accuracy: 1.0000 - val_loss: 1.7734e-12\n",
      "Epoch 405/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2111 - val_accuracy: 1.0000 - val_loss: 5.8471e-13\n",
      "Epoch 406/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2011 - val_accuracy: 1.0000 - val_loss: 9.1362e-13\n",
      "Epoch 407/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2107 - val_accuracy: 1.0000 - val_loss: 1.9373e-12\n",
      "Epoch 408/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2202 - val_accuracy: 1.0000 - val_loss: 2.7649e-12\n",
      "Epoch 409/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.1933 - val_accuracy: 1.0000 - val_loss: 2.1372e-12\n",
      "Epoch 410/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.1894 - val_accuracy: 1.0000 - val_loss: 2.5798e-12\n",
      "Epoch 411/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2010 - val_accuracy: 1.0000 - val_loss: 8.7193e-13\n",
      "Epoch 412/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2044 - val_accuracy: 1.0000 - val_loss: 8.3279e-13\n",
      "Epoch 413/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.1954 - val_accuracy: 1.0000 - val_loss: 4.7732e-13\n",
      "Epoch 414/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.1863 - val_accuracy: 1.0000 - val_loss: 4.3288e-13\n",
      "Epoch 415/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2091 - val_accuracy: 1.0000 - val_loss: 8.0515e-13\n",
      "Epoch 416/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.2051 - val_accuracy: 1.0000 - val_loss: 8.3090e-13\n",
      "Epoch 417/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.1931 - val_accuracy: 1.0000 - val_loss: 5.3485e-13\n",
      "Epoch 418/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.1869 - val_accuracy: 1.0000 - val_loss: 5.1445e-13\n",
      "Epoch 419/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.1988 - val_accuracy: 1.0000 - val_loss: 2.1205e-13\n",
      "Epoch 420/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.1922 - val_accuracy: 1.0000 - val_loss: 2.1597e-13\n",
      "Epoch 421/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.1796 - val_accuracy: 1.0000 - val_loss: 2.3714e-13\n",
      "Epoch 422/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2273 - val_accuracy: 1.0000 - val_loss: 1.3648e-13\n",
      "Epoch 423/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.1997 - val_accuracy: 1.0000 - val_loss: 4.4463e-14\n",
      "Epoch 424/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.1895 - val_accuracy: 1.0000 - val_loss: 6.5938e-14\n",
      "Epoch 425/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.1878 - val_accuracy: 1.0000 - val_loss: 7.2005e-14\n",
      "Epoch 426/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.2117 - val_accuracy: 1.0000 - val_loss: 1.9844e-14\n",
      "Epoch 427/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.1866 - val_accuracy: 1.0000 - val_loss: 2.5897e-14\n",
      "Epoch 428/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.1815 - val_accuracy: 1.0000 - val_loss: 1.7721e-14\n",
      "Epoch 429/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.1974 - val_accuracy: 1.0000 - val_loss: 3.8237e-14\n",
      "Epoch 430/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.1797 - val_accuracy: 1.0000 - val_loss: 5.3694e-14\n",
      "Epoch 431/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.1795 - val_accuracy: 1.0000 - val_loss: 7.8242e-14\n",
      "Epoch 432/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.1967 - val_accuracy: 1.0000 - val_loss: 6.0999e-14\n",
      "Epoch 433/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.1926 - val_accuracy: 1.0000 - val_loss: 1.6794e-13\n",
      "Epoch 434/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2186 - val_accuracy: 1.0000 - val_loss: 1.3315e-13\n",
      "Epoch 435/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.1863 - val_accuracy: 1.0000 - val_loss: 4.2169e-13\n",
      "Epoch 436/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2051 - val_accuracy: 1.0000 - val_loss: 2.7845e-13\n",
      "Epoch 437/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.1858 - val_accuracy: 1.0000 - val_loss: 3.5509e-13\n",
      "Epoch 438/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2177 - val_accuracy: 1.0000 - val_loss: 1.4421e-13\n",
      "Epoch 439/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.1960 - val_accuracy: 1.0000 - val_loss: 7.4571e-14\n",
      "Epoch 440/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.1987 - val_accuracy: 1.0000 - val_loss: 5.7874e-14\n",
      "Epoch 441/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2135 - val_accuracy: 1.0000 - val_loss: 1.1752e-13\n",
      "Epoch 442/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.1897 - val_accuracy: 1.0000 - val_loss: 3.5663e-13\n",
      "Epoch 443/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2027 - val_accuracy: 1.0000 - val_loss: 6.9438e-14\n",
      "Epoch 444/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.1867 - val_accuracy: 1.0000 - val_loss: 9.6826e-14\n",
      "Epoch 445/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1807 - val_accuracy: 1.0000 - val_loss: 1.4858e-13\n",
      "Epoch 446/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.1878 - val_accuracy: 1.0000 - val_loss: 1.9840e-13\n",
      "Epoch 447/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.1792 - val_accuracy: 1.0000 - val_loss: 1.5573e-13\n",
      "Epoch 448/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.1687 - val_accuracy: 1.0000 - val_loss: 3.7583e-14\n",
      "Epoch 449/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.1892 - val_accuracy: 1.0000 - val_loss: 8.5818e-14\n",
      "Epoch 450/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.1915 - val_accuracy: 1.0000 - val_loss: 1.0868e-13\n",
      "Epoch 451/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.1879 - val_accuracy: 1.0000 - val_loss: 1.2063e-13\n",
      "Epoch 452/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.1723 - val_accuracy: 1.0000 - val_loss: 9.5556e-14\n",
      "Epoch 453/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.1956 - val_accuracy: 1.0000 - val_loss: 5.9245e-14\n",
      "Epoch 454/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.1918 - val_accuracy: 1.0000 - val_loss: 3.6942e-14\n",
      "Epoch 455/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2092 - val_accuracy: 1.0000 - val_loss: 3.0320e-14\n",
      "Epoch 456/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2041 - val_accuracy: 1.0000 - val_loss: 1.4390e-14\n",
      "Epoch 457/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.1992 - val_accuracy: 1.0000 - val_loss: 2.7286e-13\n",
      "Epoch 458/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.2109 - val_accuracy: 1.0000 - val_loss: 4.1733e-13\n",
      "Epoch 459/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.1938 - val_accuracy: 1.0000 - val_loss: 1.4156e-13\n",
      "Epoch 460/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.1989 - val_accuracy: 1.0000 - val_loss: 6.4439e-14\n",
      "Epoch 461/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.1679 - val_accuracy: 1.0000 - val_loss: 4.7926e-14\n",
      "Epoch 462/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.1582 - val_accuracy: 1.0000 - val_loss: 2.8671e-14\n",
      "Epoch 463/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.1880 - val_accuracy: 1.0000 - val_loss: 2.4680e-14\n",
      "Epoch 464/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9326 - loss: 0.1716 - val_accuracy: 1.0000 - val_loss: 1.8489e-14\n",
      "Epoch 465/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2090 - val_accuracy: 1.0000 - val_loss: 2.1372e-14\n",
      "Epoch 466/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.1928 - val_accuracy: 1.0000 - val_loss: 6.4354e-14\n",
      "Epoch 467/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.1843 - val_accuracy: 1.0000 - val_loss: 1.3644e-13\n",
      "Epoch 468/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.1957 - val_accuracy: 1.0000 - val_loss: 2.7109e-13\n",
      "Epoch 469/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1783 - val_accuracy: 1.0000 - val_loss: 4.3977e-14\n",
      "Epoch 470/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.1942 - val_accuracy: 1.0000 - val_loss: 7.0481e-15\n",
      "Epoch 471/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.1738 - val_accuracy: 1.0000 - val_loss: 4.3516e-15\n",
      "Epoch 472/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.1815 - val_accuracy: 1.0000 - val_loss: 1.2740e-15\n",
      "Epoch 473/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1760 - val_accuracy: 1.0000 - val_loss: 1.2279e-15\n",
      "Epoch 474/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.1837 - val_accuracy: 1.0000 - val_loss: 7.2942e-16\n",
      "Epoch 475/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.1697 - val_accuracy: 1.0000 - val_loss: 6.8784e-16\n",
      "Epoch 476/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.1771 - val_accuracy: 1.0000 - val_loss: 6.6198e-16\n",
      "Epoch 477/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.1812 - val_accuracy: 1.0000 - val_loss: 3.5236e-16\n",
      "Epoch 478/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.1911 - val_accuracy: 1.0000 - val_loss: 2.2675e-16\n",
      "Epoch 479/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.1858 - val_accuracy: 1.0000 - val_loss: 1.2247e-16\n",
      "Epoch 480/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.1964 - val_accuracy: 1.0000 - val_loss: 1.1674e-15\n",
      "Epoch 481/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.1848 - val_accuracy: 1.0000 - val_loss: 2.5985e-15\n",
      "Epoch 482/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1753 - val_accuracy: 1.0000 - val_loss: 4.3393e-15\n",
      "Epoch 483/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.1823 - val_accuracy: 1.0000 - val_loss: 3.3936e-15\n",
      "Epoch 484/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.1923 - val_accuracy: 1.0000 - val_loss: 7.8431e-15\n",
      "Epoch 485/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.1874 - val_accuracy: 1.0000 - val_loss: 7.1690e-15\n",
      "Epoch 486/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.1917 - val_accuracy: 1.0000 - val_loss: 1.9668e-15\n",
      "Epoch 487/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.1966 - val_accuracy: 1.0000 - val_loss: 1.1692e-15\n",
      "Epoch 488/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.1766 - val_accuracy: 1.0000 - val_loss: 2.2533e-15\n",
      "Epoch 489/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.1706 - val_accuracy: 1.0000 - val_loss: 3.1862e-15\n",
      "Epoch 490/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.1817 - val_accuracy: 1.0000 - val_loss: 8.4696e-16\n",
      "Epoch 491/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2067 - val_accuracy: 1.0000 - val_loss: 1.0144e-15\n",
      "Epoch 492/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.1786 - val_accuracy: 1.0000 - val_loss: 7.0132e-16\n",
      "Epoch 493/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.1961 - val_accuracy: 1.0000 - val_loss: 1.3156e-15\n",
      "Epoch 494/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.1987 - val_accuracy: 1.0000 - val_loss: 1.9992e-15\n",
      "Epoch 495/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.1914 - val_accuracy: 1.0000 - val_loss: 2.2565e-15\n",
      "Epoch 496/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.1831 - val_accuracy: 1.0000 - val_loss: 1.7914e-15\n",
      "Epoch 497/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.1840 - val_accuracy: 1.0000 - val_loss: 1.0136e-15\n",
      "Epoch 498/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.1916 - val_accuracy: 1.0000 - val_loss: 9.0373e-16\n",
      "Epoch 499/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.1845 - val_accuracy: 1.0000 - val_loss: 3.5729e-15\n",
      "Epoch 500/500\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.1915 - val_accuracy: 1.0000 - val_loss: 1.2692e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a30d7bb61b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Build ANN model\n",
    "def build_ann(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=input_dim, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "ann = build_ann(X_combined.shape[1])\n",
    "\n",
    "# Train ANN\n",
    "ann.fit(X_combined, y_combined, epochs=500, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Test Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "# loss, accuracy = ann.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "y_pred=ann.predict(X_test)\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(y_test,y_pred_bin)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 28 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a30d53b7740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a30d464b380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhav/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Cross-validation accuracies: [0.8699186991869918, 0.8699186991869918, 0.8780487804878049, 0.8734693877551021, 0.8979591836734694]\n",
      "Mean cross-validation accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "cv_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, val_index in kf.split(X_combined):\n",
    "    X_train_cv, X_val_cv = X_combined[train_index], X_combined[val_index]\n",
    "    y_train_cv, y_val_cv = y_combined[train_index], y_combined[val_index]\n",
    "    \n",
    "    # Build and compile the ANN model\n",
    "    ann_cv = build_ann(X_combined.shape[1])\n",
    "    \n",
    "    # Train the model\n",
    "    ann_cv.fit(X_train_cv, y_train_cv, epochs=500, batch_size=64, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred = ann_cv.predict(X_val_cv)\n",
    "    y_val_pred_bin = (y_val_pred > 0.5).astype(int)\n",
    "    val_acc = accuracy_score(y_val_cv, y_val_pred_bin)\n",
    "    cv_accuracies.append(val_acc)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-validation accuracies: {cv_accuracies}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(cv_accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after applying cross validation is 0.88\n"
     ]
    }
   ],
   "source": [
    "acc_gan_cv = np.mean(cv_accuracies)\n",
    "print(f'Accuracy after applying cross validation is {(acc_gan_cv):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot cross-validation accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cv_accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('Cross-Validation Accuracy of ANN Model')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Diabetic       0.81      0.77      0.79        99\n",
      "    Diabetic       0.62      0.67      0.64        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.72      0.72       154\n",
      "weighted avg       0.74      0.73      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get precison,accuracy,recall,f1-score\n",
    "from sklearn.metrics import classification_report\n",
    "#in tabuluar format\n",
    "print(classification_report(y_test, y_pred_bin, target_names=['Not Diabetic', 'Diabetic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "dt_model = DecisionTreeClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "knn_model = KNeighborsClassifier()\n",
    "svc_model = SVC()\n",
    "gb_model = GradientBoostingClassifier()\n",
    "nb_model = GaussianNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train, y_train)\n",
    "svc_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and calculate accuracy\n",
    "dt_acc = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "rf_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "knn_acc = accuracy_score(y_test, knn_model.predict(X_test))\n",
    "svc_acc = accuracy_score(y_test, svc_model.predict(X_test))\n",
    "gb_acc = accuracy_score(y_test, gb_model.predict(X_test))\n",
    "nb_acc = accuracy_score(y_test, nb_model.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.75\n",
      "Random Forest Accuracy: 0.75\n",
      "KNN Accuracy: 0.69\n",
      "SVM Accuracy: 0.75\n",
      "Gradient Boosting Accuracy: 0.75\n",
      "Naive Bayes Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Print accuracies\n",
    "print(f\"Decision Tree Accuracy: {dt_acc:.2f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.2f}\")\n",
    "print(f\"KNN Accuracy: {knn_acc:.2f}\")\n",
    "print(f\"SVM Accuracy: {svc_acc:.2f}\")\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.2f}\")\n",
    "print(f\"Naive Bayes Accuracy: {nb_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "rgba(50, 171, 96, 0.6)",
          "line": {
           "color": "rgba(50, 171, 96, 1.0)",
           "width": 1
          }
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.7532467532467533,
          0.7467532467532467,
          0.6883116883116883,
          0.7467532467532467,
          0.7467532467532467,
          0.7662337662337663,
          0.877862950058072
         ],
         "y": [
          "Decision Tree",
          "Random Forest",
          "KNN",
          "SVM",
          "Gradient Boosting",
          "Naive Bayes",
          "GAN"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Accuracies Comparison"
        },
        "xaxis": {
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis": {
         "title": {
          "text": "Model"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Model names and their accuracies\n",
    "model_names = ['Decision Tree', 'Random Forest', 'KNN', 'SVM', 'Gradient Boosting', 'Naive Bayes','GAN']\n",
    "accuracies = [dt_acc, rf_acc, knn_acc, svc_acc, gb_acc, nb_acc,acc_gan_cv]\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=accuracies,\n",
    "    y=model_names,\n",
    "    orientation='h',\n",
    "    marker=dict(color='rgba(50, 171, 96, 0.6)', line=dict(color='rgba(50, 171, 96, 1.0)', width=1))\n",
    "))\n",
    "\n",
    "# Update layout for better look\n",
    "fig.update_layout(\n",
    "    title='Model Accuracies Comparison',\n",
    "    xaxis=dict(title='Accuracy'),\n",
    "    yaxis=dict(title='Model'),\n",
    "    template='plotly_white'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preg=int(input(\"Enter the number of pregnancies: \"))\n",
    "glucose=int(input(\"Enter the glucose level: \"))\n",
    "blood_pressure=int(input(\"Enter the blood pressure: \"))\n",
    "skin_thickness=int(input(\"Enter the skin thickness: \"))\n",
    "insulin=int(input(\"Enter the insulin level: \"))\n",
    "bmi=float(input(\"Enter the BMI: \"))\n",
    "diabetes_pedigree_function=float(input(\"Enter the diabetes pedigree function: \"))\n",
    "age=int(input(\"Enter the age: \"))\n",
    "input_data = [preg, glucose, blood_pressure, skin_thickness, insulin, bmi, diabetes_pedigree_function, age]\n",
    "input_data = np.array(input_data).reshape(1, -1)\n",
    "input_data = scaler.transform(input_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction: 1.00\n",
      "Diabetic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction = ann_cv.predict(input_data)\n",
    "print(f\"Prediction: {prediction[0][0]:.2f}\")\n",
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Diabetic\")\n",
    "else:\n",
    "    print(\"Not Diabetic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
